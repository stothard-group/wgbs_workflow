from os.path import join
from os import listdir
import pandas as pd


# snakemake --snakefile workflow/snakefile --cluster "sbatch -N 1 -c {resources.cores} \
# --mem={resources.mem_mb} --time={resources.runtime} --account=account" --rerun-incomplete --printshellcmds -j 20

#########################################################################################
# Path to config file
#########################################################################################
configfile: 'config/WGBS.config.yaml'

#########################################################################################
# Set local variables
#########################################################################################
RAW_FASTQ_DIR = config["raw_fastq_dir"]
OUTPUT_DIR = "results/"
SPLIT_DIR = OUTPUT_DIR + "split/"
TRIMGALORE_DIR = OUTPUT_DIR + "trimmed/"
ALIGN_DIR = OUTPUT_DIR + "align/"
GENOME_DIR = config["genome_dir"]
GENOME_BASENAME = config["genome_base"]
RECAL_DIR = OUTPUT_DIR + "base_quality_recal/"
STAT_DIR = OUTPUT_DIR + "stat_and_coverage/"
CGMAP_DIR = OUTPUT_DIR + "cgmap/"
BENCHMARK_DIR = OUTPUT_DIR + "benchmark/"



READGROUP_FILE = config["readgroup_file"]
TRIMGALORE = config["trimgalore"]
CGMAPTOOLS = config["cgmaptools"]

MIN_COVERAGE_DEPTH = config["min_coverage_depth"]
n_of_chunks = config["n_of_chunks"]

#########################################################################################
# Define samples
#########################################################################################
samples, = glob_wildcards(join(RAW_FASTQ_DIR + "{sample}_R1.fastq.gz"))

def get_combined_samples():
    rg_list = pd.read_csv(READGROUP_FILE, sep='\t')
    sam_list_all = rg_list['SM'].tolist()
    sam_list = list(set(sam_list_all))
    return sam_list

list_of_samples = get_combined_samples()

#########################################################################################
# rule to trigger generation of target files
#########################################################################################
rule final:
    input:
        expand(SPLIT_DIR + "{sample}_R1_part{new}.fastq.gz", sample=samples, new=range(n_of_chunks)),
        expand(TRIMGALORE_DIR + "{sample}_R1_part{new}.trimmed.fastq.gz", sample=samples, new=range(n_of_chunks)), #  trimming
        GENOME_DIR + "Bisulfite_Genome/CT_conversion/BS_CT.1.bt2", #  build genome index
        expand(RECAL_DIR+ "{sample}.deduplicated.rgid.bam", sample=samples), # add read group IDs
        expand(RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.sorted.bam", sample_list_val=list_of_samples), #  sort merged bam files
        expand(RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.sorted.bam.bai", sample_list_val=list_of_samples), #  index sorted bismark files
        expand(CGMAP_DIR + "{sample_list_val}.bayes_dynamicP.SNPs.vcf", sample_list_val=list_of_samples), #  get SNPs



#########################################################################################
# split input files
#########################################################################################

rule split:
    input:
        r1 = RAW_FASTQ_DIR + "{sample}_R1.fastq.gz",
        r2 = RAW_FASTQ_DIR + "{sample}_R2.fastq.gz"

    threads: 1
    resources:
        cores = 1,
        runtime = 480,
        mem_mb = 20000,
    output:
        r1 = expand(SPLIT_DIR + "{{sample}}_R1_part{new}.fastq.gz", new=range(n_of_chunks)),
        r2 = expand(SPLIT_DIR + "{{sample}}_R2_part{new}.fastq.gz", new=range(n_of_chunks))
    params:
        r1 = lambda wildcards: SPLIT_DIR  + wildcards.sample + '_R1_part',
        r2 = lambda wildcards: SPLIT_DIR  + wildcards.sample + '_R2_part',
    shell:
        """
        partition.sh -Xmx{resources.mem_mb}m in={input.r1} in2={input.r2} out={params.r1}%.fastq.gz \
                out2={params.r2}%.fastq.gz ways={n_of_chunks}; \
        touch {output.r1}; \
        touch {output.r2}
        """

#########################################################################################
# run trimgalore on raw data
#########################################################################################

# Use --2colour 20 for NovaSeq6000 samples
rule trimgalore:
    input:
        R1 = (SPLIT_DIR + "{sample}_R1_part{new}.fastq.gz"),
        R2 = (SPLIT_DIR + "{sample}_R2_part{new}.fastq.gz")
    output:
        R1 = TRIMGALORE_DIR + "{sample}_R1_part{new}.trimmed.fastq.gz",
        R2 = TRIMGALORE_DIR + "{sample}_R2_part{new}.trimmed.fastq.gz"
    benchmark:
        BENCHMARK_DIR + "trimgalore.{sample}_part{new}.txt"
    threads: 4
    resources:
        cores= 4,
        mem_mb= 32000,
        runtime= 600
    shell:
        """
        module load python/3.9
        module load fastqc
        {TRIMGALORE} --cores {threads}  --paired --gzip {input.R1} {input.R2}  -o {TRIMGALORE_DIR}
        """


#########################################################################################
# prep genome for bismark
#########################################################################################

rule prep_genome:
    input:
        GENOME_DIR + GENOME_BASENAME + ".fa"
    output:
        GENOME_DIR + "Bisulfite_Genome/CT_conversion/BS_CT.1.bt2"
    params:
        GENOME_DIR
    benchmark:
        BENCHMARK_DIR + "prep_genome.txt"
    threads: 8
    resources:
        cores= 8,
        mem_mb= 32000,
        runtime= 240
    shell:
        """
        module load samtools perl StdEnv/2020 bismark bowtie2
        bismark_genome_preparation --parallel {threads} {params} 
        """

#########################################################################################
# run bismark
#########################################################################################

rule align:
    input:
        R1 = TRIMGALORE_DIR + "{sample}_R1_part{new}.trimmed.fastq.gz",
        R2 = TRIMGALORE_DIR + "{sample}_R2_part{new}.trimmed.fastq.gz",
        g_complete = GENOME_DIR + "Bisulfite_Genome/CT_conversion/BS_CT.1.bt2"
    benchmark:
        BENCHMARK_DIR + "align.{sample}_part{new}.txt"
    params:
        tmpdir = "./tmp_{sample}_part{new}"
    threads: 4 # PARALLEL 4 ~ 24 THREADS AND 48GB RAM, DO NOT CHANGE WITHOUT READING BISMARK README
    resources:
        cores= 24,
        mem_mb= 48000,
        runtime= 240
    output:
        ALIGN_DIR + "{sample}_R1_part{new}.trimmed_bismark_bt2_pe.bam"
    shell:
        """
        module load samtools perl StdEnv/2020 bismark bowtie2
        bismark --genome {GENOME_DIR} -1 {input.R1} -2 {input.R2} \
        --old_flag --no_dovetail \
        --parallel {threads} \
        --temp_dir {params.tmpdir} \
        -o {ALIGN_DIR}
        """

#########################################################################################
# merge files and sort prior to deduplication
#########################################################################################

rule merge_bams:
    input:
        bam = expand(ALIGN_DIR + "{{sample}}_R1_part{new}.trimmed_bismark_bt2_pe.bam",
            new=[str(i) for i in list(range(n_of_chunks))]),
    output:
        ALIGN_DIR + "{sample}.bismark.m.bam"
    resources:
        cores = 1,
        runtime = 360,
        mem_mb = 4000,
    params:
        bam = ' '.join(["I=" + ALIGN_DIR + "{sample}_part" + str(new) + ".trimmed_bismark_bt2_pe.bam" for new in \
                list(range(n_of_chunks))]),
    shell:
        """
        module load java
        module load picard
        java -Xmx{resources.mem_mb}m -jar $EBROOTPICARD/picard.jar MergeSamFiles {params.bam} O={output} --SORT_ORDER queryname
        """

#########################################################################################
# bisulfite data deduplication
#########################################################################################

rule dedup:
    input:
        ALIGN_DIR + "{sample}.bismark.m.bam"
    output:
        RECAL_DIR + "{sample}.deduplicated.bam"
    benchmark:
        BENCHMARK_DIR + "dedup.{sample}.txt"
    threads: 4
    resources:
        cores= 4,
        mem_mb= 8000,
        runtime= 240
    params:
        lambda wildcards: wildcards.sample
    shell:
        """
        module load samtools perl StdEnv/2020 bismark bowtie2
        deduplicate_bismark -p \
        --output_dir {RECAL_DIR} -o {params} \
        {input}
        """

#########################################################################################
# add read group information # Note - do this here rather than with bt2
#########################################################################################


def get_rg_label(sample):
    split_sample = sample.split(".")
    sample_id_part = split_sample[4]
    rg_list = pd.read_csv(READGROUP_FILE, sep='\t')
    line = rg_list[rg_list['SM'] == int(sample_id_part)].copy()
    ID = line['ID'].values[0]
    LB = line['LB'].values[0]
    SM = line['SM'].values[0]
    PL = line['PL'].values[0]
    PU = ID + "." + str(SM)
    rg_label = [ID, str(SM), PL, str(LB), PU]
    return rg_label


rule add_rgids:
    input:
        RECAL_DIR + "{sample}.deduplicated.bam"
    output:
        RECAL_DIR + "{sample}.deduplicated.rgid.bam"
    benchmark:
        BENCHMARK_DIR + "add_rgids.{sample}.txt"
    params:
        RG_label = lambda wildcards: get_rg_label('{sample}'.format(sample=wildcards.sample))
    threads: 4
    resources:
        cores= 4,
        mem_mb= 8000,
        runtime= 240
    shell:
        """
        module load java
        module load picard
        java -Xmx{resources.mem_mb}m -jar $EBROOTPICARD/picard.jar \
        AddOrReplaceReadGroups \
        I={input} O={output} \
        --RGID {params.RG_label[0]} \
        --RGSM {params.RG_label[1]} \
        --RGPL {params.RG_label[2]} \
        --RGLB {params.RG_label[3]} \
        --RGPU {params.RG_label[4]} \
        --CREATE_INDEX=true --VALIDATION_STRINGENCY=SILENT --SORT_ORDER=queryname
        """

#########################################################################################
# merge sample files
#########################################################################################

def merge_sample_list(sample_name):
    """
    Generates an input line for Picard MergeSamFiles for samples that need to be aggregated
    :param sample_name: base name of a sample (not the whole file name)
    :return: -I FC1_L1_SAM1.bam -I FC1_L2_SAM1.bam -I FC2_L1_SAM1.bam
    """
    if os.path.exists(RECAL_DIR):
        aligndir_files = os.listdir(RECAL_DIR)
        m_bam_list = []
        for file in aligndir_files:
            if file.endswith(".deduplicated.rgid.bam"):
                m_bam_list.append(file)
        keep_bams = []
        for bam in m_bam_list:
            split_bam_name = bam.split(".")
            if sample_name == split_bam_name[4]:
                keep_bams.append(bam)
        input_string = ''
        for kept_bam in keep_bams:
            input_string = input_string + "I=" + RECAL_DIR + kept_bam + " "
        new_input_string = input_string[:-1]
    else:
        new_input_string=''
    return new_input_string

rule merge:
    input:
        expand(RECAL_DIR + "{sample}.deduplicated.rgid.bam", sample=samples)
    params:
        input_line = lambda wildcards: merge_sample_list('{val}'.format(val=wildcards.sample_list_val)),
        tmpdir= "./tmp_{sample_list_val}"
    benchmark:
        BENCHMARK_DIR + "merge.{sample_list_val}.txt"
    threads: 4
    resources:
        cores= 4,
        mem_mb= 8000,
        runtime= 240
    output:
        RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.bam"
    shell:
        """
        module load java
        module load picard
        mkdir -p {params.tmpdir};
        java -Xmx{resources.mem_mb}m -jar $EBROOTPICARD/picard.jar \
        MergeSamFiles \ 
        {params.input_line} \
        O={output} \
        SORT_ORDER=queryname
        """

#########################################################################################
# Sort merged bismark alignment files
#########################################################################################

rule sortsam:
    input:
        RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.bam"
    output:
        RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.sorted.bam"
    benchmark:
        BENCHMARK_DIR + "sortsam.{sample_list_val}.txt"
    threads: 4
    resources:
        cores= 4,
        mem_mb= 8000,
        runtime= 240
    shell:
        """
        module load java
        module load picard
        java -Xmx{resources.mem_mb}m -jar $EBROOTPICARD/picard.jar \
        SortSam \
        I={input} O={output} \
        SORT_ORDER=coordinate        
        """


#########################################################################################
# Index sorted bismark files
#########################################################################################

rule b_index:
    input:
        RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.sorted.bam"
    output:
        RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.sorted.bam.bai"
    benchmark:
        BENCHMARK_DIR + "b_index.{sample_list_val}.txt"
    threads: 1
    resources:
        cores= 1,
        mem_mb= 2000,
        runtime= 30
    shell:
        """
        module load samtools
        samtools index {input}
        """

#########################################################################################
# Get coverage and alignment statistics
#########################################################################################

rule coverage:
    input:
        align = RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.sorted.bam",
        index = RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.sorted.bam.bai"
    output:
        depth = STAT_DIR + "{sample_list_val}.average_coverage.txt",
        mpileup = STAT_DIR + "{sample_list_val}.bases_covered.txt",
        alignstats = STAT_DIR + "{sample_list_val}.alignment_stats.txt"
    benchmark:
        BENCHMARK_DIR + "coverage.{sample_list_val}.txt"
    threads: 1
    resources:
        cores= 1,
        mem_mb= 2000,
        runtime= 120
    shell:
        """
        module load samtools
        samtools depth {input.align} | awk '{{sum+=$3}} END {{ print "Average = ",sum/NR}}' > {output.depth}
        samtools mpileup {input.align} |  awk -v X="{MIN_COVERAGE_DEPTH}" '$4>=X' | wc -l > {output.mpileup}
        samtools flagstat {input.align} > {output.alignstats}
        """

#########################################################################################
# Make DNA methylation profiles (ATCGmaps) from alignments
#########################################################################################

rule cgmap_conversion:
    input:
        align = RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.sorted.bam",
        index = RECAL_DIR + "{sample_list_val}.deduplicated.rgid.m.sorted.bam.bai"
    output:
        CGMAP_DIR + "{sample_list_val}.ATCGmap.gz"
    benchmark:
        BENCHMARK_DIR + "cgmap_conversion.{sample_list_val}.txt"
    params:
        out = lambda wildcards: CGMAP_DIR + wildcards.sample_list_val,
        genome = GENOME_DIR + GENOME_BASENAME + ".fa"
    threads: 16
    resources:
        cores= 16,
        mem_mb= 64000,
        runtime= 720
    shell:
        """
        {CGMAPTOOLS} convert bam2cgmap -b {input.align} \
        -g {params.genome} \
        --rmOverlap \
        -o {params.out}
        """

#########################################################################################
# Run CGmapTools with bayes and bayes-dynamicP to get SNPs
#########################################################################################

rule cgmap_bayes:
    input:
        CGMAP_DIR + "{sample_list_val}.ATCGmap.gz"
    output:
        vcf= CGMAP_DIR + "{sample_list_val}.bayes_dynamicP.SNPs.vcf",
        out = CGMAP_DIR + "{sample_list_val}.bayes_dynamicP.SNPs.snv"
    benchmark:
        BENCHMARK_DIR + "cpmap_bayes.{sample_list_val}.txt"
    threads: 16
    resources:
        cores= 16,
        mem_mb= 64000,
        runtime= 720
    shell:
        """
        {CGMAPTOOLS} snv -i {input} \
        -o {output.out} -v {output.vcf} \
        -m bayes --bayes-dynamicP
        """
